{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMpA2ZpAnewslF7wWhGaqq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYKXhx31Y_bs","executionInfo":{"status":"ok","timestamp":1758275964988,"user_tz":-330,"elapsed":4607,"user":{"displayName":"Sham Gawande","userId":"15923927462468499230"}},"outputId":"573854c5-e014-425b-9193-bad77dd7a73a"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF version: 2.19.0\n"]}],"source":["import tensorflow as tf\n","print(\"TF version:\", tf.__version__)"]},{"cell_type":"code","source":["try:\n","  # %tensorflow_version only exists in Colab\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGhPUns7Z_BW","executionInfo":{"status":"ok","timestamp":1758275946378,"user_tz":-330,"elapsed":31,"user":{"displayName":"Sham Gawande","userId":"15923927462468499230"}},"outputId":"a0007d5a-1851-4cd2-9aa3-373866986e41"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}]},{"cell_type":"code","source":["# Import necessary tools\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","print(\"TF version:\", tf.__version__)\n","print(\"TF Hub version:\", hub.__version__)\n","\n","# Check for GPU availability\n","print(\"GPU\", \"available (YESSSS!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imz6QZ1qZ_6u","executionInfo":{"status":"ok","timestamp":1758276000537,"user_tz":-330,"elapsed":1511,"user":{"displayName":"Sham Gawande","userId":"15923927462468499230"}},"outputId":"29e0d6f7-7f37-4d30-b858-e9281977b8f1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["TF version: 2.19.0\n","TF Hub version: 0.16.1\n","GPU not available :(\n"]}]},{"cell_type":"code","source":["# Checkout the labels of our data\n","import pandas as pd\n","labels_csv = pd.read_csv(\"drive/My Drive/Dog Vision/labels.csv\")\n","print(labels_csv.describe())\n","print(labels_csv.head())"],"metadata":{"id":"VNxFKWMmaAXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's view an image\n","from IPython.display import Image\n","Image(\"drive/My Drive/Dog Vision/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")"],"metadata":{"id":"WS-Trj4xaAsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create pathnames from image ID's\n","filenames = [\"drive/My Drive/Dog Vision/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n","\n","# Check the first 10\n","filenames[:10]"],"metadata":{"id":"izLX3l_sa5tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","labels = labels_csv[\"breed\"].to_numpy()\n","# labels = np.array(labels) # does same thing as above\n","labels"],"metadata":{"id":"3spe976Ia6AF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# See if number of labels matches the number of filenames\n","if len(labels) == len(filenames):\n","  print(\"Number of labels matches number of filenames!\")\n","else:\n","  print(\"Number of labels does not match number of filenames, check data directories!\")\n"],"metadata":{"id":"crBBsxj6a6Rs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find the unique label values\n","unique_breeds = np.unique(labels)\n","len(unique_breeds)\n","unique_breeds"],"metadata":{"id":"Sf-Zy4Jra6j8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn a single label into an array of booleans\n","print(labels[0])\n","labels[0] == unique_breeds"],"metadata":{"id":"P5ERmTcGa60s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn every label into a boolean array\n","boolean_labels = [label == unique_breeds for label in labels]\n","boolean_labels[:2]"],"metadata":{"id":"aJvE7tsXa7Eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example: Turning boolean array into integers\n","print(labels[0]) # original label\n","print(np.where(unique_breeds == labels[0])) # index where label occurs\n","print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n","print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"],"metadata":{"id":"92v8sE1aa7TC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup X & y variables\n","X = filenames\n","y = boolean_labels\n","len(filenames)"],"metadata":{"id":"5IUaSfFea7pK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set number of images to use for experimenting\n","NUM_IMAGES = 1000\n","\n","# Let's split our data into train and validation sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split them into training and validation of total size NUM_IMAGES\n","X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n","                                                  y[:NUM_IMAGES],\n","                                                  test_size=0.2,\n","                                                  random_state=42)\n","\n","len(X_train), len(y_train), len(X_val), len(y_val)"],"metadata":{"id":"kdqVt536ecti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's have a geez at the training data\n","X_train[:5], y_train[:2]"],"metadata":{"id":"Y7RwVTWva8G_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert image to NumPy array\n","from matplotlib.pyplot import imread\n","image = imread(filenames[42])\n","image.shape"],"metadata":{"id":"FlGU7zxZa8VN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image.max(), image.min()\n","image[:2]"],"metadata":{"id":"BU_fbDZDa8me"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define image size\n","IMG_SIZE = 224\n","\n","# Create a function for preprocessing images\n","def process_image(image_path, img_size=IMG_SIZE):\n","  \"\"\"\n","  Takes an image file path and turns the image into a Tensor.\n","  \"\"\"\n","  # Read in an image file\n","  image = tf.io.read_file(image_path)\n","  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  # Convert the colour channel values from 0-255 to 0-1 values\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  # Resize the image to our desired value (224, 224)\n","  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n","\n","  return image"],"metadata":{"id":"FRpCyoqsa8z7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a simple function to return a tuple (image, label)\n","def get_image_label(image_path, label):\n","  \"\"\"\n","  Takes an image file path name and the assosciated label,\n","  processes the image and reutrns a typle of (image, label).\n","  \"\"\"\n","  image = process_image(image_path)\n","  return image, label\n","\n","# Demo of the above\n","(process_image(X[42]), tf.constant(y[42]))"],"metadata":{"id":"T0BrEKrBa9B8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the batch size, 32 is a good start\n","BATCH_SIZE = 32\n","\n","# Create a function to turn data into batches\n","def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n","  \"\"\"\n","  Creates batches of data out of image (X) and label (y) pairs.\n","  Shuffles the data if it's training data but doesn't shuffle if it's validation data.\n","  Also accepts test data as input (no labels).\n","  \"\"\"\n","  # If the data is a test dataset, we probably don't have have labels\n","  if test_data:\n","    print(\"Creating test data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n","    data_batch = data.map(process_image).batch(BATCH_SIZE)\n","    return data_batch\n","\n","  # If the data is a valid dataset, we don't need to shuffle it\n","  elif valid_data:\n","    print(\"Creating validation data batches...\")\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n","                                               tf.constant(y))) # labels\n","    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n","    return data_batch\n","\n","  else:\n","    print(\"Creating training data batches...\")\n","    # Turn filepaths and labels into Tensors\n","    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n","                                               tf.constant(y)))\n","    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n","    data = data.shuffle(buffer_size=len(X))\n","\n","    # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n","    data = data.map(get_image_label)\n","\n","    # Turn the training data into batches\n","    data_batch = data.batch(BATCH_SIZE)\n","  return data_batch"],"metadata":{"id":"ppGM6f1ja9Ni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create training and validation data batches\n","train_data = create_data_batches(X_train, y_train)\n","val_data = create_data_batches(X_val, y_val, valid_data=True)"],"metadata":{"id":"6ob3je1Bff1n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Create a function for viewing images in a data batch\n","def show_25_images(images, labels):\n","  \"\"\"\n","  Displays a plot of 25 images and their labels from a data batch.\n","  \"\"\"\n","  # Setup the figure\n","  plt.figure(figsize=(10, 10))\n","  # Loop through 25 (for displaying 25 images)\n","  for i in range(25):\n","    # Create subplots (5 rows, 5 columns)\n","    ax = plt.subplot(5, 5, i+1)\n","    # Display an image\n","    plt.imshow(images[i])\n","    # Add the image label as the title\n","    plt.title(unique_breeds[labels[i].argmax()])\n","    # Turn the grid lines off\n","    plt.axis(\"off\")\n","\n","\n","train_data"],"metadata":{"id":"MnN2Zk07fgHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE\n","\n","# Setup input shape to the model\n","INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n","\n","# Setup output shape of our model\n","OUTPUT_SHAPE = len(unique_breeds)\n","\n","# Setup model URL from TensorFlow Hub\n","MODEL_URL =\n","\n","INPUT_SHAPE"],"metadata":{"id":"OfOvCfowfgWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a function which builds a Keras model\n","def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n","  print(\"Building model with:\", MODEL_URL)\n","\n","  # Setup the model layers\n","  model = tf.keras.Sequential([\n","    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n","    tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n","                          activation=\"softmax\") # Layer 2 (output layer)\n","  ])\n","\n","  # Compile the model\n","  model.compile(\n","      loss=tf.keras.losses.CategoricalCrossentropy(),\n","      optimizer=tf.keras.optimizers.Adam(),\n","      metrics=[\"accuracy\"]\n","  )\n","\n","  # Build the model\n","  model.build(INPUT_SHAPE)\n","\n","  return model\n","\n","\n","model = create_model()\n","model.summary()"],"metadata":{"id":"xvoGr0ZOfgjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load TensorBoard notebook extension\n","%load_ext tensorboard\n","import datetime\n","\n","# Create a function to build a TensorBoard callback\n","def create_tensorboard_callback():\n","  # Create a log directory for storing TensorBoard logs\n","  logdir = os.path.join(\"drive/My Drive/Dog Vision/logs\",\n","                        # Make it so the logs get tracked whenever we run an experiment\n","                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  return tf.keras.callbacks.TensorBoard(logdir)"],"metadata":{"id":"IeD1fltOfgxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create early stopping callback\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n","                                                  patience=3)"],"metadata":{"id":"N7rvXZF7fg8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}\n","\n","# Check to make sure we're still running on a GPU\n","print(\"GPU\", \"available (YESSS!!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"],"metadata":{"id":"PK4NPmG9fh-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build a function to train and return a trained model\n","def train_model():\n","  \"\"\"\n","  Trains a given model and returns the trained version.\n","  \"\"\"\n","  # Create a model\n","  model = create_model()\n","\n","  # Create new TensorBoard session everytime we train a model\n","  tensorboard = create_tensorboard_callback()\n","\n","  # Fit the model to the data passing it the callbacks we created\n","  model.fit(x=train_data,\n","            epochs=NUM_EPOCHS,\n","            validation_data=val_data,\n","            validation_freq=1,\n","            callbacks=[tensorboard, early_stopping])\n","  # Return the fitted model\n","  return model\n","\n","\n","# Fit the model to the data\n","model = train_model()"],"metadata":{"id":"6Ffw-FoPfiKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(val_data, verbose=1)\n","predictions"],"metadata":{"id":"FGDU-pTZgmtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First prediction\n","index = 42\n","print(predictions[index])\n","print(f\"Max value (probability of prediction): {np.max(predictions[index])}\")\n","print(f\"Sum: {np.sum(predictions[index])}\")\n","print(f\"Max index: {np.argmax(predictions[index])}\")\n","print(f\"Predicted label: {unique_breeds[np.argmax(predictions[index])]}\")"],"metadata":{"id":"PfJ_-hkUfiWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn prediction probabilities into their respective label (easier to understand)\n","def get_pred_label(prediction_probabilities):\n","  \"\"\"\n","  Turns an array of prediction probabilities into a label.\n","  \"\"\"\n","  return unique_breeds[np.argmax(prediction_probabilities)]\n","\n","# Get a predicted label based on an array of prediction probabilities\n","pred_label = get_pred_label(predictions[81])\n","pred_label"],"metadata":{"id":"NvTavnzigoLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a function to unbatch a batch dataset\n","def unbatchify(data):\n","  \"\"\"\n","  Takes a batched dataset of (image, label) Tensors and reutrns separate arrays\n","  of images and labels.\n","  \"\"\"\n","  images = []\n","  labels = []\n","  # Loop through unbatched data\n","  for image, label in data.unbatch().as_numpy_iterator():\n","    images.append(image)\n","    labels.append(unique_breeds[np.argmax(label)])\n","  return images, labels\n","\n","# Unbatchify the validation data\n","val_images, val_labels = unbatchify(val_data)\n","val_images[0], val_labels[0]"],"metadata":{"id":"DNowRw_6gn8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_pred(prediction_probabilities, labels, images, n=1):\n","  \"\"\"\n","  View the prediction, ground truth and image for sample n\n","  \"\"\"\n","  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n","\n","  # Get the pred label\n","  pred_label = get_pred_label(pred_prob)\n","\n","  # Plot image & remove ticks\n","  plt.imshow(image)\n","  plt.xticks([])\n","  plt.yticks([])\n","\n","  # Change the colour of the title depending on if the prediction is right or wrong\n","  if pred_label == true_label:\n","    color = \"green\"\n","  else:\n","    color = \"red\"\n","\n","  # Change plot title to be predicted, probability of prediction and truth label\n","  plt.title(\"{} {:2.0f}% {}\".format(pred_label,\n","                                    np.max(pred_prob)*100,\n","                                    true_label),\n","                                    color=color)\n","\n","\n","plot_pred(prediction_probabilities=predictions,\n","          labels=val_labels,\n","          images=val_images,\n","          n=77)"],"metadata":{"id":"jExJxiJJhF00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_pred_conf(prediction_probabilities, labels, n=1):\n","  \"\"\"\n","  Plus the top 10 highest prediction confidences along with the truth label for sample n.\n","  \"\"\"\n","  pred_prob, true_label = prediction_probabilities[n], labels[n]\n","\n","  # Get the predicted label\n","  pred_label = get_pred_label(pred_prob)\n","\n","  # Find the top 10 prediction confidence indexes\n","  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n","  # Find the top 10 prediction confidence values\n","  top_10_pred_values = pred_prob[top_10_pred_indexes]\n","  # Find the top 10 prediction labels\n","  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n","\n","  # Setup plot\n","  top_plot = plt.bar(np.arange(len(top_10_pred_labels)),\n","                     top_10_pred_values,\n","                     color=\"grey\")\n","  plt.xticks(np.arange(len(top_10_pred_labels)),\n","             labels=top_10_pred_labels,\n","             rotation=\"vertical\")\n","\n","  # Change color of true label\n","  if np.isin(true_label, top_10_pred_labels):\n","    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n","  else:\n","    pass\n","\n","\n","plot_pred_conf(prediction_probabilities=predictions,\n","               labels=val_labels,\n","               n=9)"],"metadata":{"id":"Sp2bCf3-hFpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's check out a few predictions and their different values\n","i_multiplier = 20\n","num_rows = 3\n","num_cols = 2\n","num_images = num_rows*num_cols\n","plt.figure(figsize=(10*num_cols, 5*num_rows))\n","for i in range(num_images):\n","  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","  plot_pred(prediction_probabilities=predictions,\n","            labels=val_labels,\n","            images=val_images,\n","            n=i+i_multiplier)\n","  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","  plot_pred_conf(prediction_probabilities=predictions,\n","                 labels=val_labels,\n","                 n=i+i_multiplier)\n","plt.tight_layout(h_pad=1.0)\n","plt.show()"],"metadata":{"id":"SWEg64MVhFdC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a function to save a model\n","def save_model(model, suffix=None):\n","  \"\"\"\n","  Saves a given model in a models directory and appends a suffix (string).\n","  \"\"\"\n","  # Create a model directory pathname with current time\n","  modeldir = os.path.join(\"drive/My Drive/Dog Vision/models\",\n","                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n","  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n","  print(f\"Saving model to: {model_path}...\")\n","  model.save(model_path)\n","  return model_path\n","\n","\n","# Create a function to load a trained model\n","def load_model(model_path):\n","  \"\"\"\n","  Loads a saved model from a specified path.\n","  \"\"\"\n","  print(f\"Loading saved model from: {model_path}\")\n","  model = tf.keras.models.load_model(model_path,\n","                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n","  return model"],"metadata":{"id":"QV9wYW6FhFSz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save our model trained on 1000 images\n","save_model(model, suffix=\"1000-images-mobilenetv2-Adam\")"],"metadata":{"id":"1oLH1opyhFE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aUIk-arKh1Hg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P72kHI0Ch1D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xgGqUw_Sh1Bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zeiRt6mZh0-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lgYrhfi_h08X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YjEiHt-5h056"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MyfM3cP8h03X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fZ0c-PcEh002"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l1mMzIPRh0s5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y30H3L6mh0dm"},"execution_count":null,"outputs":[]}]}